{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dd1e5aa",
   "metadata": {},
   "source": [
    "# 04 — Final Model Training & Winner Prediction\n",
    "\n",
    "This notebook trains and evaluates the **final NBA team points prediction model**  \n",
    "using the cleaned dataset (`data/processed/team_games_clean.csv`).\n",
    "\n",
    "It:\n",
    "\n",
    "1. Loads processed game-level team data.\n",
    "2. Performs a chronological 80/20 train–test split.\n",
    "3. Trains a **Linear Regression** model to predict team points (`pts`).\n",
    "4. Compares performance to a **team-average baseline** using MAE and RMSE.\n",
    "5. Converts score predictions into **game winner predictions**.\n",
    "6. Compares winner accuracy to a **home-team baseline**.\n",
    "\n",
    "The goal is to provide a minimal, reproducible pipeline for the final report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdba59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data path: ../data/processed/team_games_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Paths relative to this notebook (living in notebooks/)\n",
    "CLEAN_PATH = Path(\"../data/processed/team_games_clean.csv\")\n",
    "\n",
    "MODEL_DIR = Path(\"../models\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "MODEL_PATH = MODEL_DIR / \"final_linear_regression.joblib\"\n",
    "\n",
    "PRED_PATH = Path(\"../data/processed/test_predictions.csv\")\n",
    "\n",
    "print(\"Cleaned data path:\", CLEAN_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f479a564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: ../data/processed/team_games_clean.csv | shape: (2460, 35)\n",
      "Columns: ['season_id', 'team_id', 'team_abbreviation', 'team_name', 'game_id', 'game_date', 'matchup', 'wl', 'pts', 'fg_pct', 'fga', 'fgm', 'fg3m', 'fg3a', 'fg3_pct', 'ftm', 'fta', 'ft_pct', 'oreb', 'dreb', 'reb', 'ast', 'stl', 'blk', 'tov', 'pf', 'plus_minus', 'home', 'rest_days', 'opponent_team_id', 'opponent_team_abbreviation', 'opponent_pts', 'opponent_fg_pct', 'opponent_reb', 'opponent_tov']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ATL',\n",
       " 'BKN',\n",
       " 'BOS',\n",
       " 'CHA',\n",
       " 'CHI',\n",
       " 'CLE',\n",
       " 'DAL',\n",
       " 'DEN',\n",
       " 'DET',\n",
       " 'GSW',\n",
       " 'HOU',\n",
       " 'IND',\n",
       " 'LAC',\n",
       " 'LAL',\n",
       " 'MEM',\n",
       " 'MIA',\n",
       " 'MIL',\n",
       " 'MIN',\n",
       " 'NOP',\n",
       " 'NYK',\n",
       " 'OKC',\n",
       " 'ORL',\n",
       " 'PHI',\n",
       " 'PHX',\n",
       " 'POR',\n",
       " 'SAC',\n",
       " 'SAS',\n",
       " 'TOR',\n",
       " 'UTA',\n",
       " 'WAS']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(CLEAN_PATH, parse_dates=[\"game_date\"])\n",
    "print(\"Loaded:\", CLEAN_PATH, \"| shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "# Optional: peek at the first few rows\n",
    "df.head()\n",
    "sorted(df[\"team_abbreviation\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a858177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1968, 35) | Test: (492, 35)\n",
      "Train date range: 2023-10-24 00:00:00 → 2024-03-14 00:00:00\n",
      "Test date range:  2024-03-14 00:00:00 → 2024-04-14 00:00:00\n"
     ]
    }
   ],
   "source": [
    "TARGET = \"pts\"\n",
    "\n",
    "CANDIDATE_FEATURES = [\n",
    "    \"home\", \"rest_days\",\n",
    "    \"fg_pct\", \"fga\", \"fgm\",\n",
    "    \"reb\", \"ast\", \"tov\",\n",
    "    \"opponent_pts\", \"opponent_fg_pct\", \"opponent_reb\", \"opponent_tov\",\n",
    "]\n",
    "\n",
    "# Chronological sort\n",
    "df = df.sort_values(\"game_date\").reset_index(drop=True)\n",
    "\n",
    "split_idx = int(len(df) * 0.8)\n",
    "train_df = df.iloc[:split_idx].copy()\n",
    "test_df = df.iloc[split_idx:].copy()\n",
    "\n",
    "print(f\"Train: {train_df.shape} | Test: {test_df.shape}\")\n",
    "print(f\"Train date range: {train_df['game_date'].min()} → {train_df['game_date'].max()}\")\n",
    "print(f\"Test date range:  {test_df['game_date'].min()} → {test_df['game_date'].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab09a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in candidate features (train):\n",
      "home               0\n",
      "rest_days          0\n",
      "fg_pct             0\n",
      "fga                0\n",
      "fgm                0\n",
      "reb                0\n",
      "ast                0\n",
      "tov                0\n",
      "opponent_pts       0\n",
      "opponent_fg_pct    0\n",
      "opponent_reb       0\n",
      "opponent_tov       0\n",
      "dtype: int64\n",
      "\n",
      "Training samples: 1968\n",
      "Test samples:     492\n",
      "Features used:    ['home', 'rest_days', 'fg_pct', 'fga', 'fgm', 'reb', 'ast', 'tov', 'opponent_pts', 'opponent_fg_pct', 'opponent_reb', 'opponent_tov']\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values in candidate features (train):\")\n",
    "print(train_df[CANDIDATE_FEATURES].isna().sum())\n",
    "print()\n",
    "\n",
    "# Drop rows with missing values in features (same strategy as 03)\n",
    "X_train = train_df[CANDIDATE_FEATURES].dropna()\n",
    "y_train = train_df.loc[X_train.index, TARGET]\n",
    "\n",
    "X_test = test_df[CANDIDATE_FEATURES].dropna()\n",
    "y_test = test_df.loc[X_test.index, TARGET]\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples:     {len(X_test)}\")\n",
    "print(f\"Features used:    {CANDIDATE_FEATURES}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd46f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BASELINE MODEL (Team Season Average) ===\n",
      "MAE:  10.15\n",
      "RMSE: 12.54\n"
     ]
    }
   ],
   "source": [
    "# Baseline: team-season-average points, computed on training data only\n",
    "team_avg = train_df.groupby(\"team_abbreviation\")[TARGET].mean().to_dict()\n",
    "\n",
    "test_with_baseline = test_df.loc[y_test.index].copy()\n",
    "test_with_baseline[\"baseline_pred\"] = test_with_baseline[\"team_abbreviation\"].map(team_avg)\n",
    "\n",
    "baseline_mae = mean_absolute_error(test_with_baseline[TARGET], test_with_baseline[\"baseline_pred\"])\n",
    "baseline_rmse = np.sqrt(mean_squared_error(test_with_baseline[TARGET], test_with_baseline[\"baseline_pred\"]))\n",
    "\n",
    "print(\"=== BASELINE MODEL (Team Season Average) ===\")\n",
    "print(f\"MAE:  {baseline_mae:.2f}\")\n",
    "print(f\"RMSE: {baseline_rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe655a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL MODEL: Linear Regression ===\n",
      "MAE:  4.08\n",
      "RMSE: 5.14\n",
      "\n",
      "Improvement in MAE vs baseline:  6.07 points\n",
      "Improvement in RMSE vs baseline: 7.39 points\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "lr_mae = mean_absolute_error(y_test, y_pred)\n",
    "lr_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"=== FINAL MODEL: Linear Regression ===\")\n",
    "print(f\"MAE:  {lr_mae:.2f}\")\n",
    "print(f\"RMSE: {lr_rmse:.2f}\")\n",
    "print()\n",
    "print(f\"Improvement in MAE vs baseline:  {baseline_mae - lr_mae:.2f} points\")\n",
    "print(f\"Improvement in RMSE vs baseline: {baseline_rmse - lr_rmse:.2f} points\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027d7bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>team_abbreviation</th>\n",
       "      <th>home</th>\n",
       "      <th>pts</th>\n",
       "      <th>predicted_pts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>22300959</td>\n",
       "      <td>DAL</td>\n",
       "      <td>0</td>\n",
       "      <td>119</td>\n",
       "      <td>117.440002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>22300958</td>\n",
       "      <td>PHI</td>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "      <td>106.163445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>22300958</td>\n",
       "      <td>MIL</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>111.710105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>22300960</td>\n",
       "      <td>POR</td>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>94.198519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>22300957</td>\n",
       "      <td>HOU</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>134.481287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       game_id team_abbreviation  home  pts  predicted_pts\n",
       "1968  22300959               DAL     0  119     117.440002\n",
       "1969  22300958               PHI     0  105     106.163445\n",
       "1970  22300958               MIL     1  114     111.710105\n",
       "1971  22300960               POR     1   93      94.198519\n",
       "1972  22300957               HOU     1  135     134.481287"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Attach predictions back to a clean test subset\n",
    "test_pred_df = test_df.loc[y_test.index].copy()\n",
    "test_pred_df[\"predicted_pts\"] = y_pred\n",
    "\n",
    "required_cols = [\"game_id\", \"team_abbreviation\", \"home\", TARGET, \"predicted_pts\"]\n",
    "missing = [c for c in required_cols if c not in test_pred_df.columns]\n",
    "if missing:\n",
    "    print(\"WARNING: Missing columns needed for winner prediction:\", missing)\n",
    "else:\n",
    "    display(test_pred_df[required_cols].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432f2543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== WINNER PREDICTION (Score-based) ===\n",
      "Accuracy: 0.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ct/lrcvk3k942j5nqm_cp6qc1900000gn/T/ipykernel_2248/2005410438.py:6: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.loc[g[TARGET].idxmax(), \"team_abbreviation\"])\n",
      "/var/folders/ct/lrcvk3k942j5nqm_cp6qc1900000gn/T/ipykernel_2248/2005410438.py:14: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.loc[g[\"predicted_pts\"].idxmax(), \"team_abbreviation\"])\n"
     ]
    }
   ],
   "source": [
    "if not missing:\n",
    "    # Actual winners: team with highest ACTUAL pts in each game\n",
    "    actual_winners = (\n",
    "        test_pred_df\n",
    "        .groupby(\"game_id\")\n",
    "        .apply(lambda g: g.loc[g[TARGET].idxmax(), \"team_abbreviation\"])\n",
    "        .rename(\"actual_winner\")\n",
    "    )\n",
    "\n",
    "    # Predicted winners: team with highest PREDICTED pts in each game\n",
    "    predicted_winners = (\n",
    "        test_pred_df\n",
    "        .groupby(\"game_id\")\n",
    "        .apply(lambda g: g.loc[g[\"predicted_pts\"].idxmax(), \"team_abbreviation\"])\n",
    "        .rename(\"predicted_winner\")\n",
    "    )\n",
    "\n",
    "    winner_df = pd.concat([actual_winners, predicted_winners], axis=1)\n",
    "    winner_accuracy = (winner_df[\"actual_winner\"] == winner_df[\"predicted_winner\"]).mean()\n",
    "\n",
    "    print(\"=== WINNER PREDICTION (Score-based) ===\")\n",
    "    print(f\"Accuracy: {winner_accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c2676e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BASELINE WINNER PREDICTION (Home Team) ===\n",
      "Accuracy: 0.522\n",
      "\n",
      "Comparison:\n",
      "Score-based model accuracy: 0.818\n",
      "Home-team baseline accuracy: 0.522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ct/lrcvk3k942j5nqm_cp6qc1900000gn/T/ipykernel_2248/3908449126.py:6: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.loc[g[\"home\"].idxmax(), \"team_abbreviation\"])\n"
     ]
    }
   ],
   "source": [
    "if not missing:\n",
    "    # Baseline winner: always pick home team\n",
    "    baseline_home_winner = (\n",
    "        test_pred_df\n",
    "        .groupby(\"game_id\")\n",
    "        .apply(lambda g: g.loc[g[\"home\"].idxmax(), \"team_abbreviation\"])\n",
    "        .rename(\"baseline_winner\")\n",
    "    )\n",
    "\n",
    "    baseline_accuracy = (baseline_home_winner == actual_winners).mean()\n",
    "\n",
    "    print(\"=== BASELINE WINNER PREDICTION (Home Team) ===\")\n",
    "    print(f\"Accuracy: {baseline_accuracy:.3f}\")\n",
    "\n",
    "    print(\"\\nComparison:\")\n",
    "    print(f\"Score-based model accuracy: {winner_accuracy:.3f}\")\n",
    "    print(f\"Home-team baseline accuracy: {baseline_accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba013188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test predictions to: ../data/processed/test_predictions.csv\n",
      "Saved trained Linear Regression model to: ../models/final_linear_regression.joblib\n"
     ]
    }
   ],
   "source": [
    "# Save test predictions\n",
    "if not missing:\n",
    "    out_cols = [\"game_id\", \"team_abbreviation\", \"home\", TARGET, \"predicted_pts\"]\n",
    "    preds_out = test_pred_df[out_cols].copy()\n",
    "    PRED_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    preds_out.to_csv(PRED_PATH, index=False)\n",
    "    print(\"Saved test predictions to:\", PRED_PATH)\n",
    "\n",
    "# Save trained model\n",
    "joblib.dump(lr, MODEL_PATH)\n",
    "print(\"Saved trained Linear Regression model to:\", MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21b663e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FINAL MODEL SUMMARY\n",
      "============================================================\n",
      "Target: pts\n",
      "Train samples: 1968\n",
      "Test samples:  492\n",
      "\n",
      "Regression performance (test set):\n",
      "- Baseline MAE / RMSE: 10.15 / 12.54\n",
      "- Linear  MAE / RMSE: 4.08 / 5.14\n",
      "\n",
      "Winner prediction:\n",
      "- Score-based model accuracy: 0.818\n",
      "- Home-team baseline accuracy: 0.522\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"FINAL MODEL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Target: {TARGET}\")\n",
    "print(f\"Train samples: {len(X_train)}\")\n",
    "print(f\"Test samples:  {len(X_test)}\")\n",
    "print()\n",
    "print(\"Regression performance (test set):\")\n",
    "print(f\"- Baseline MAE / RMSE: {baseline_mae:.2f} / {baseline_rmse:.2f}\")\n",
    "print(f\"- Linear  MAE / RMSE: {lr_mae:.2f} / {lr_rmse:.2f}\")\n",
    "print()\n",
    "if not missing:\n",
    "    print(\"Winner prediction:\")\n",
    "    print(f\"- Score-based model accuracy: {winner_accuracy:.3f}\")\n",
    "    print(f\"- Home-team baseline accuracy: {baseline_accuracy:.3f}\")\n",
    "print(\"=\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs506-nba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
